params:
- train
- --help
output:
  exit_code: 0
  stdout: |
    Usage: base-callback train [OPTIONS]

    Options:
      --distributed / --no-distributed
                                      If the learner is distributed.  [default: no-
                                      distributed]
      --fp16 / --no-fp16              Whether or not the floating-point precision of
                                      learner should be set to 16 bit.  [default:
                                      fp16]
      --output-dir PATH               The location of the output directory.
                                      [default: ./outputs]
      --project-name TEXT             The name for this project for logging
                                      purposes.
      --wandb / --no-wandb            Whether or not to use 'Weights and Biases' for
                                      logging.  [default: no-wandb]
      --wandb-mode TEXT               The mode for 'Weights and Biases'.  [default:
                                      online]
      --wandb-dir PATH                The location for 'Weights and Biases' output.
      --mlflow / --no-mlflow          Whether or not to use MLflow for logging.
                                      [default: no-mlflow]
      --csv PATH                      The path to a CSV file with the data.
      --x TEXT                        The column name of the independent variable.
                                      [default: x]
      --y TEXT                        The column name of the dependent variable.
                                      [default: y]
      --validation-proportion FLOAT   The proportion of the dataset to use for
                                      validation.  [default: 0.2]
      --batch-size INTEGER            The number of items to use in each batch.
                                      [default: 32]
      --epochs INTEGER                The number of epochs.  [default: 20]
      --freeze-epochs INTEGER         The number of epochs to train when the learner
                                      is frozen and the last layer is trained by
                                      itself. Only if `fine_tune` is set on the app.
                                      [default: 3]
      --learning-rate FLOAT           The base learning rate (when fine tuning) or
                                      the max learning rate otherwise.  [default:
                                      0.0001]
      --help                          Show this message and exit.
